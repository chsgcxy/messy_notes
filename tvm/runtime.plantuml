@startuml runtime

rectangle greaph_runtime.creat {
    (根据python传入的ctx, 构建c++内部定义的TVMContext vector) as creat_step1
    
    (实例化第三方软件dmlc的JSONReader) as creat_step2
    note right
        dmlc(Distributed Machine Learning Common Codebase)
        分布式机器学习通用代码库,
        提供了构建高效且可扩展的分布式机器学习库的能力
        GraphRuntime 依赖于 JSONReader
    endnote
    
    (利用JSONReader将graph.json转化为内部数据结构, 完成load过程) as creat_step3

    (将graph的attrs_.dltype转换为TVMType) as creat_step4
    note left
        "attrs": {
            "dltype": [
                "list_str", 
                [
                    "float32", 
                    "float32",
                ]
            ],
    endnote

    (构建池节点pool_entry) as creat_step5
    note left
        bytes = dltype[i] * shape[i]
        从所有节点中给出每个storage_id对应的节点的bytes最大值
    endnote

    (每个storage_id对应的storage_pool_使用DeviceAPI AllocDataSpace) as creat_step6
    note right
        所有的target的实现都继承于DeviceAPI接口
        DeviceAPI 受 DeviceAPIManager 管理
        通过 "device_api." + target 的方式可以找到具体 DeviceAPI
        具体 DeviceAPI 通过 TVM_REGISTER_GLOBAL 进行注册
        具体 DeviceAPI 分布在 src/runtime 主目录及各个子目录下
    endnote

    (根据storage_pool_ 构建 data_entry_, 完成SetupStorage过程) as creat_step7

    (遍历graph中所有非‘null’节点，\n \
    构建DLTensor向量， \n \
    并且获取每一个node的func组成op_execs_向量) as creat_step8

    creat_step1 -right-> creat_step2
    creat_step2 -down-> creat_step3
    creat_step3 -left-> creat_step4
    creat_step4 -down-> creat_step5
    creat_step5 -right-> creat_step6
    creat_step6 -down-> creat_step7
    creat_step7 -left-> creat_step8

    (creat end) as ce    
    creat_step8 --> ce
}

rectangle "tvm build result"{
    (Graph)
    note left
        a string of dict, similar to str({})
        "{
            "nodes": [
                {
                    "op": "null",
                    "name": "x",
                    "inputs": []
                },
                {
                    "op": "tvm_op",
                    "name": "relu0",
                    "attrs": {      
                        "flatten_data": "0",
                        "func_name": "fuse_l2_normalize_relu",
                        "num_inputs": "1",                    
                        "num_outputs": "1"                    
                    },
                    "inputs": [[0, 0, 0]]  
                }
            ],
            "arg_nodes": [0],
            "node_row_ptr": [0, 1, 2],
            "heads": [[1, 0, 0]],
            ......
        }"
    endnote
    (Graph) ..> creat_step1
    
    (Lib)
    note left
        a Module object, contain lib.so
    endnote
    (Lib) ..> creat_step1
    
    (params)
    note left
        a dict contains node params ...
        {'p22': <tvm.NDArray shape=(8, 16, 3, 3, 8, 32), cpu(0)>
            array([[[[[[-2.49230769e-02,  2.73413258e-03, ...,
             7.61547452e-03, -6.19848166e-03, -2.52313819e-02],
           [ 2.66786274e-02,  4.06193052e-04,  5.14294626e-03, ...,
            -3.45390639e-03,  4.50841105e-03,  5.40218735e-03],
         ......
        }
    endnote
}

(ctx)
note left
    a object class TVMContext or a list of TVMContext
    tvm.cpu(0)
    tvm.gpu(0)
    tvm.opencl(0)
endnote
(ctx) ..> creat_step1

(GraphModule)
note right
    a wrapper of class GraphRuntime in c++
    本质上是一个Module实例，这个实例作为container包含了GraphRuntime实例
endnote
ce --> (GraphModule): return a object of GraphModule

(picture image data) as input_data

(调用set_input完成参数输入) as set_input
note right
    call by PackedFunc GraphRuntime::GetFunction from python to c++
    将输入数据copy到data_entry_对应的node里面
    如果输入参数是param，循环是在python侧完成的
    c++ 接口每次只接受一个node的数据
endnote
params ..> set_input
input_data ..> set_input
(GraphModule) --> set_input


(GraphModule.run) as run
note right
    so easy.............

    void GraphRuntime::Run() {
    // setup the array and requirements.
    for (size_t i = 0; i < op_execs_.size(); ++i) {
        if (op_execs_[i]) op_execs_[i]();
    }
    }
endnote
set_input --> run

(GraphModule.get_output) as get_output
note right
    从data_entry_中获取输出节点数据
    graph 中heads字段保存了输出note信息
    heads is a list of entries as the output of the graph.
    在Init阶段便解析到了GraphRuntime的outputs_字段中
endnote
run --> get_output

@enduml